# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# Allow crawling of all content
User-agent: *
Allow: /

# Disallow crawling of Genkit specific paths if any are exposed
# User-agent: *
# Disallow: /api/genkit/

Sitemap: /sitemap.xml
